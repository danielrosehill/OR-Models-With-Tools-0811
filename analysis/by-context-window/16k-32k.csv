model_name,model_id,vendor,context_length,input_price_usd_per_m,output_price_usd_per_m,description
Mistral: Voxtral Small 24B 2507,mistralai/voxtral-small-24b-2507,mistralai,32000,0.1,0.3,"Voxtral Small is an enhancement of Mistral Small 3, incorporating state-of-the-art audio input capabilities while retaining best-in-class text performance. It excels at speech transcription, translation and audio understanding. Input audio is priced at $100 per million seconds."
Baidu: ERNIE 4.5 VL 28B A3B,baidu/ernie-4.5-vl-28b-a3b,baidu,30000,0.14,0.56,"A powerful multimodal Mixture-of-Experts chat model featuring 28B total parameters with 3B activated per token, delivering exceptional text and vision understanding through its innovative heterogeneous MoE structure with modality-isolated routing. Built with scaling-efficient infrastructure for high-throughput training and inference, the model leverages advanced post-training techniques including SFT, DPO, and UPO for optimized performance, while supporting an impressive 131K context length and RLVR alignment for superior cross-modal reasoning and generation capabilities."
Cogito V2 Preview Llama 109B,deepcogito/cogito-v2-preview-llama-109b-moe,deepcogito,32767,0.18,0.59,"An instruction-tuned, hybrid-reasoning Mixture-of-Experts model built on Llama-4-Scout-17B-16E. Cogito v2 can answer directly or engage an extended “thinking” phase, with alignment guided by Iterated Distillation & Amplification (IDA). It targets coding, STEM, instruction following, and general helpfulness, with stronger multilingual, tool-calling, and reasoning performance than size-equivalent baselines. The model supports long-context use (up to 10M tokens) and standard Transformers workflows. Users can control the reasoning behaviour with the `reasoning` `enabled` boolean. [Learn more in our docs](https://openrouter.ai/docs/use-cases/reasoning-tokens#enable-reasoning-with-default-config)"
OpenAI: GPT-3.5 Turbo,openai/gpt-3.5-turbo,openai,16385,0.5,1.5,"GPT-3.5 Turbo is OpenAI's fastest model. It can understand and generate natural language or code, and is optimized for chat and traditional completion tasks.  Training data up to Sep 2021."
OpenAI: GPT-3.5 Turbo 16k,openai/gpt-3.5-turbo-16k,openai,16385,3.0,4.0,"This model offers four times the context length of gpt-3.5-turbo, allowing it to support approximately 20 pages of text in a single request at a higher cost. Training data: up to Sep 2021."
