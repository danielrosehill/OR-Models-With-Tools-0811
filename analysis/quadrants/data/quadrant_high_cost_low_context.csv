model_name,model_id,vendor,context_length,input_price_usd_per_m,output_price_usd_per_m,avg_cost,quadrant,value_score,description
Qwen: Qwen3 Coder Flash,qwen/qwen3-coder-flash,qwen,128000,0.3,1.5,0.9,High Cost / Low Context,142222.22222222222,"Qwen3 Coder Flash is Alibaba's fast and cost efficient version of their proprietary Qwen3 Coder Plus. It is a powerful coding agent model specializing in autonomous programming via tool calling and environment interaction, combining coding proficiency with versatile general-purpose abilities."
Microsoft: Phi-3 Medium 128K Instruct,microsoft/phi-3-medium-128k-instruct,microsoft,128000,1.0,1.0,1.0,High Cost / Low Context,128000.0,"Phi-3 128K Medium is a powerful 14-billion parameter model designed for advanced language understanding, reasoning, and instruction following. Optimized through supervised fine-tuning and preference adjustments, it excels in tasks involving common sense, mathematics, logical reasoning, and code processing.  At time of release, Phi-3 Medium demonstrated state-of-the-art performance among lightweight models. In the MMLU-Pro eval, the model even comes close to a Llama3 70B level of performance.  For 4k context length, try [Phi-3 Medium 4K](/models/microsoft/phi-3-medium-4k-instruct)."
StepFun: Step3,stepfun-ai/step3,stepfun-ai,65536,0.57,1.42,0.9949999999999999,High Cost / Low Context,65865.32663316584,"Step3 is a cutting-edge multimodal reasoning model—built on a Mixture-of-Experts architecture with 321B total parameters and 38B active. It is designed end-to-end to minimize decoding costs while delivering top-tier performance in vision–language reasoning. Through the co-design of Multi-Matrix Factorization Attention (MFA) and Attention-FFN Disaggregation (AFD), Step3 maintains exceptional efficiency across both flagship and low-end accelerators."
Z.AI: GLM 4.5V,z-ai/glm-4.5v,z-ai,65536,0.6,1.8,1.2,High Cost / Low Context,54613.333333333336,"GLM-4.5V is a vision-language foundation model for multimodal agent applications. Built on a Mixture-of-Experts (MoE) architecture with 106B parameters and 12B activated parameters, it achieves state-of-the-art results in video understanding, image Q&A, OCR, and document parsing, with strong gains in front-end web coding, grounding, and spatial reasoning. It offers a hybrid inference mode: a ""thinking mode"" for deep reasoning and a ""non-thinking mode"" for fast responses. Reasoning behavior can be toggled via the `reasoning` `enabled` boolean. [Learn more in our docs](https://openrouter.ai/docs/use-cases/reasoning-tokens#enable-reasoning-with-default-config)"
Qwen: Qwen3 Coder Plus,qwen/qwen3-coder-plus,qwen,128000,1.0,5.0,3.0,High Cost / Low Context,42666.666666666664,"Qwen3 Coder Plus is Alibaba's proprietary version of the Open Source Qwen3 Coder 480B A35B. It is a powerful coding agent model specializing in autonomous programming via tool calling and environment interaction, combining coding proficiency with versatile general-purpose abilities."
Meta: Llama 3.1 405B Instruct,meta-llama/llama-3.1-405b-instruct,meta-llama,32768,0.8,0.8,0.8,High Cost / Low Context,40960.0,"The highly anticipated 400B class of Llama3 is here! Clocking in at 128k context with impressive eval scores, the Meta AI team continues to push the frontier of open-source LLMs.  Meta's latest class of model (Llama 3.1) launched with a variety of sizes & flavors. This 405B instruct-tuned version is optimized for high quality dialogue usecases.  It has demonstrated strong performance compared to leading closed-source models including GPT-4o and Claude 3.5 Sonnet in evaluations.  To read more about the model release, [click here](https://ai.meta.com/blog/meta-llama-3-1/). Usage of this model is subject to [Meta's Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/)."
Mistral: Magistral Small 2506,mistralai/magistral-small-2506,mistralai,40000,0.5,1.5,1.0,High Cost / Low Context,40000.0,"Magistral Small is a 24B parameter instruction-tuned model based on Mistral-Small-3.1 (2503), enhanced through supervised fine-tuning on traces from Magistral Medium and further refined via reinforcement learning. It is optimized for reasoning and supports a wide multilingual range, including over 20 languages."
Deep Cogito: Cogito V2 Preview Llama 70B,deepcogito/cogito-v2-preview-llama-70b,deepcogito,32768,0.88,0.88,0.88,High Cost / Low Context,37236.36363636364,"Cogito v2 70B is a dense hybrid reasoning model that combines direct answering capabilities with advanced self-reflection. Built with iterative policy improvement, it delivers strong performance across reasoning tasks while maintaining efficiency through shorter reasoning chains and improved intuition."
Mistral Large,mistralai/mistral-large,mistralai,128000,2.0,6.0,4.0,High Cost / Low Context,32000.0,"This is Mistral AI's flagship model, Mistral Large 2 (version `mistral-large-2407`). It's a proprietary weights-available model and excels at reasoning, code, JSON, chat, and more. Read the launch announcement [here](https://mistral.ai/news/mistral-large-2407/).  It supports dozens of languages including French, German, Spanish, Italian, Portuguese, Arabic, Hindi, Russian, Chinese, Japanese, and Korean, along with 80+ coding languages including Python, Java, C, C++, JavaScript, and Bash. Its long context window allows precise information recall from large documents."
OpenAI: GPT-4o (2024-08-06),openai/gpt-4o-2024-08-06,openai,128000,2.5,10.0,6.25,High Cost / Low Context,20480.0,"The 2024-08-06 version of GPT-4o offers improved performance in structured outputs, with the ability to supply a JSON schema in the respone_format. Read more [here](https://openai.com/index/introducing-structured-outputs-in-the-api/).  GPT-4o (""o"" for ""omni"") is OpenAI's latest AI model, supporting both text and image inputs with text outputs. It maintains the intelligence level of [GPT-4 Turbo](/models/openai/gpt-4-turbo) while being twice as fast and 50% more cost-effective. GPT-4o also offers improved performance in processing non-English languages and enhanced visual capabilities.  For benchmarking against other models, it was briefly called [""im-also-a-good-gpt2-chatbot""](https://twitter.com/LiamFedus/status/1790064963966370209)"
OpenAI: GPT-4o,openai/gpt-4o,openai,128000,2.5,10.0,6.25,High Cost / Low Context,20480.0,"GPT-4o (""o"" for ""omni"") is OpenAI's latest AI model, supporting both text and image inputs with text outputs. It maintains the intelligence level of [GPT-4 Turbo](/models/openai/gpt-4-turbo) while being twice as fast and 50% more cost-effective. GPT-4o also offers improved performance in processing non-English languages and enhanced visual capabilities.  For benchmarking against other models, it was briefly called [""im-also-a-good-gpt2-chatbot""](https://twitter.com/LiamFedus/status/1790064963966370209)  #multimodal"
OpenAI: GPT-4o Audio,openai/gpt-4o-audio-preview,openai,128000,2.5,10.0,6.25,High Cost / Low Context,20480.0,The gpt-4o-audio-preview model adds support for audio inputs as prompts. This enhancement allows the model to detect nuances within audio recordings and add depth to generated user experiences. Audio outputs are currently not supported. Audio tokens are priced at $40 per million input audio tokens.
Cohere: Command R+ (08-2024),cohere/command-r-plus-08-2024,cohere,128000,2.5,10.0,6.25,High Cost / Low Context,20480.0,"command-r-plus-08-2024 is an update of the [Command R+](/models/cohere/command-r-plus) with roughly 50% higher throughput and 25% lower latencies as compared to the previous Command R+ version, while keeping the hardware footprint the same.  Read the launch post [here](https://docs.cohere.com/changelog/command-gets-refreshed).  Use of this model is subject to Cohere's [Usage Policy](https://docs.cohere.com/docs/usage-policy) and [SaaS Agreement](https://cohere.com/saas-agreement)."
OpenAI: GPT-4o (2024-11-20),openai/gpt-4o-2024-11-20,openai,128000,2.5,10.0,6.25,High Cost / Low Context,20480.0,"The 2024-11-20 version of GPT-4o offers a leveled-up creative writing ability with more natural, engaging, and tailored writing to improve relevance & readability. It’s also better at working with uploaded files, providing deeper insights & more thorough responses.  GPT-4o (""o"" for ""omni"") is OpenAI's latest AI model, supporting both text and image inputs with text outputs. It maintains the intelligence level of [GPT-4 Turbo](/models/openai/gpt-4-turbo) while being twice as fast and 50% more cost-effective. GPT-4o also offers improved performance in processing non-English languages and enhanced visual capabilities."
OpenAI: GPT-3.5 Turbo,openai/gpt-3.5-turbo,openai,16385,0.5,1.5,1.0,High Cost / Low Context,16385.0,"GPT-3.5 Turbo is OpenAI's fastest model. It can understand and generate natural language or code, and is optimized for chat and traditional completion tasks.  Training data up to Sep 2021."
Mistral: Mixtral 8x22B Instruct,mistralai/mixtral-8x22b-instruct,mistralai,65536,2.0,6.0,4.0,High Cost / Low Context,16384.0,"Mistral's official instruct fine-tuned version of [Mixtral 8x22B](/models/mistralai/mixtral-8x22b). It uses 39B active parameters out of 141B, offering unparalleled cost efficiency for its size. Its strengths include: - strong math, coding, and reasoning - large context length (64k) - fluency in English, French, Italian, German, and Spanish  See benchmarks on the launch announcement [here](https://mistral.ai/news/mixtral-8x22b/). #moe"
OpenAI: GPT-4o (2024-05-13),openai/gpt-4o-2024-05-13,openai,128000,5.0,15.0,10.0,High Cost / Low Context,12800.0,"GPT-4o (""o"" for ""omni"") is OpenAI's latest AI model, supporting both text and image inputs with text outputs. It maintains the intelligence level of [GPT-4 Turbo](/models/openai/gpt-4-turbo) while being twice as fast and 50% more cost-effective. GPT-4o also offers improved performance in processing non-English languages and enhanced visual capabilities.  For benchmarking against other models, it was briefly called [""im-also-a-good-gpt2-chatbot""](https://twitter.com/LiamFedus/status/1790064963966370209)  #multimodal"
Mistral: Magistral Medium 2506,mistralai/magistral-medium-2506,mistralai,40960,2.0,5.0,3.5,High Cost / Low Context,11702.857142857143,Magistral is Mistral's first reasoning model. It is ideal for general purpose use requiring longer thought processing and better accuracy than with non-reasoning LLMs. From legal research and financial forecasting to software development and creative storytelling — this model solves multi-step challenges where transparency and precision are critical.
Mistral: Magistral Medium 2506 (thinking),mistralai/magistral-medium-2506:thinking,mistralai,40960,2.0,5.0,3.5,High Cost / Low Context,11702.857142857143,Magistral is Mistral's first reasoning model. It is ideal for general purpose use requiring longer thought processing and better accuracy than with non-reasoning LLMs. From legal research and financial forecasting to software development and creative storytelling — this model solves multi-step challenges where transparency and precision are critical.
OpenAI: GPT-4o (extended),openai/gpt-4o:extended,openai,128000,6.0,18.0,12.0,High Cost / Low Context,10666.666666666666,"GPT-4o (""o"" for ""omni"") is OpenAI's latest AI model, supporting both text and image inputs with text outputs. It maintains the intelligence level of [GPT-4 Turbo](/models/openai/gpt-4-turbo) while being twice as fast and 50% more cost-effective. GPT-4o also offers improved performance in processing non-English languages and enhanced visual capabilities.  For benchmarking against other models, it was briefly called [""im-also-a-good-gpt2-chatbot""](https://twitter.com/LiamFedus/status/1790064963966370209)  #multimodal"
Deep Cogito: Cogito V2 Preview Llama 405B,deepcogito/cogito-v2-preview-llama-405b,deepcogito,32768,3.5,3.5,3.5,High Cost / Low Context,9362.285714285714,Cogito v2 405B is a dense hybrid reasoning model that combines direct answering capabilities with advanced self-reflection. It represents a significant step toward frontier intelligence with dense architecture delivering performance competitive with leading closed models. This advanced reasoning system combines policy improvement with massive scale for exceptional capabilities. 
Qwen: Qwen-Max ,qwen/qwen-max,qwen,32768,1.6,6.4,4.0,High Cost / Low Context,8192.0,"Qwen-Max, based on Qwen2.5, provides the best inference performance among [Qwen models](/qwen), especially for complex multi-step tasks. It's a large-scale MoE model that has been pretrained on over 20 trillion tokens and further post-trained with curated Supervised Fine-Tuning (SFT) and Reinforcement Learning from Human Feedback (RLHF) methodologies. The parameter count is unknown."
OpenAI: GPT-4 Turbo (older v1106),openai/gpt-4-1106-preview,openai,128000,10.0,30.0,20.0,High Cost / Low Context,6400.0,The latest GPT-4 Turbo model with vision capabilities. Vision requests can now use JSON mode and function calling.  Training data: up to April 2023.
OpenAI: GPT-4 Turbo,openai/gpt-4-turbo,openai,128000,10.0,30.0,20.0,High Cost / Low Context,6400.0,The latest GPT-4 Turbo model with vision capabilities. Vision requests can now use JSON mode and function calling.  Training data: up to December 2023.
OpenAI: GPT-4 Turbo Preview,openai/gpt-4-turbo-preview,openai,128000,10.0,30.0,20.0,High Cost / Low Context,6400.0,"The preview GPT-4 model with improved instruction following, JSON mode, reproducible outputs, parallel function calling, and more. Training data: up to Dec 2023.  **Note:** heavily rate limited by OpenAI while in preview."
Sao10k: Llama 3 Euryale 70B v2.1,sao10k/l3-euryale-70b,sao10k,8192,1.48,1.48,1.48,High Cost / Low Context,5535.135135135135,"Euryale 70B v2.1 is a model focused on creative roleplay from [Sao10k](https://ko-fi.com/sao10k).  - Better prompt adherence. - Better anatomy / spatial awareness. - Adapts much better to unique and custom formatting / reply formats. - Very creative, lots of unique swipes. - Is not restrictive during roleplays."
OpenAI: GPT-3.5 Turbo 16k,openai/gpt-3.5-turbo-16k,openai,16385,3.0,4.0,3.5,High Cost / Low Context,4681.428571428572,"This model offers four times the context length of gpt-3.5-turbo, allowing it to support approximately 20 pages of text in a single request at a higher cost. Training data: up to Sep 2021."
OpenAI: GPT-3.5 Turbo (older v0613),openai/gpt-3.5-turbo-0613,openai,4095,1.0,2.0,1.5,High Cost / Low Context,2730.0,"GPT-3.5 Turbo is OpenAI's fastest model. It can understand and generate natural language or code, and is optimized for chat and traditional completion tasks.  Training data up to Sep 2021."
OpenAI: GPT-4 (older v0314),openai/gpt-4-0314,openai,8191,30.0,60.0,45.0,High Cost / Low Context,182.0222222222222,"GPT-4-0314 is the first version of GPT-4 released, with a context length of 8,192 tokens, and was supported until June 14. Training data: up to Sep 2021."
OpenAI: GPT-4,openai/gpt-4,openai,8191,30.0,60.0,45.0,High Cost / Low Context,182.0222222222222,"OpenAI's flagship model, GPT-4 is a large-scale multimodal language model capable of solving difficult problems with greater accuracy than previous models due to its broader general knowledge and advanced reasoning capabilities. Training data: up to Sep 2021."
